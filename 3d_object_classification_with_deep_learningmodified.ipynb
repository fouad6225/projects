{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fouad6225/projects/blob/main/3d_object_classification_with_deep_learningmodified.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c5d75f0",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "!pip install trimesh"
      ],
      "id": "3c5d75f0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyFDMqtjY9sb"
      },
      "outputs": [],
      "source": [
        " !pip install open3d"
      ],
      "id": "NyFDMqtjY9sb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ae9d45e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import trimesh\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "tf.random.set_seed(1234)\n"
      ],
      "id": "2ae9d45e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9b6726b",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "DATA_DIR = tf.keras.utils.get_file(\n",
        "    \"modelnet.zip\",\n",
        "    \"http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\",\n",
        "    extract=True,\n",
        ")\n",
        "DATA_DIR = os.path.join(os.path.dirname(DATA_DIR), \"ModelNet10\")\n"
      ],
      "id": "c9b6726b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkZA0Hse2-qD"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "\n",
        "\n",
        "ax.plot_trisurf(trim.vertices[:, 0], trim.vertices[:,1], trim.vertices[:,2], triangles=trim.faces)"
      ],
      "id": "CkZA0Hse2-qD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e563f04f"
      },
      "outputs": [],
      "source": [
        "trim = trimesh.load(os.path.join(DATA_DIR, \"chair/train/chair_0001.off\"))\n",
        "trim.show()\n"
      ],
      "id": "e563f04f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFezEZq-xCt4"
      },
      "outputs": [],
      "source": [],
      "id": "xFezEZq-xCt4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57af03db"
      },
      "outputs": [],
      "source": [
        "points = trim.sample(2048)\n",
        "\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "ax = fig.add_subplot(111, projection=\"3d\")\n",
        "ax.scatter(points[:, 0], points[:, 1], points[:, 2])\n",
        "ax.set_axis_off()\n",
        "plt.show()\n"
      ],
      "id": "57af03db"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1i-LyD9yviol"
      },
      "outputs": [],
      "source": [
        "\n",
        "def Normalize( pointcloud):\n",
        "        #mean\n",
        "        norm_pointcloud = pointcloud - np.mean(pointcloud, axis=0)\n",
        "        #std\n",
        "        norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))\n",
        "\n",
        "        return  norm_pointcloud\n",
        "    \n",
        "def RandomNoise(norm_pointcloud):\n",
        "    \n",
        "        #calculate random noise\n",
        "        noise = np.random.normal(0, 0.02, (norm_pointcloud.shape))\n",
        "    \n",
        "        #add noise to points\n",
        "        noisy_pointcloud = norm_pointcloud + noise\n",
        "        \n",
        "        return  noisy_pointcloud\n",
        "    \n",
        "    \n",
        "\n",
        "def RandomScale(noisy_pointcloud):\n",
        "        s = np.random.uniform(0.9, 1.1, 3)\n",
        "        \n",
        "        rot_mat = np.array([[s[0], 0, 0],\n",
        "                            [0, s[1], 0],\n",
        "                            [0, 0, s[2]]])\n",
        "        \n",
        "        return np.matmul(noisy_pointcloud, rot_mat)"
      ],
      "id": "1i-LyD9yviol"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnFC4I83lAuH"
      },
      "outputs": [],
      "source": [
        "norm_pointcloud=Normalize(points)\n",
        "noisy_pointcloud=RandomNoise(norm_pointcloud)\n",
        "pointcloud=RandomScale(noisy_pointcloud)\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "ax = fig.add_subplot(111, projection=\"3d\")\n",
        "ax.scatter(pointcloud[:, 0],pointcloud[:, 1], pointcloud[:, 2])\n",
        "ax.set_axis_off()\n",
        "plt.show()"
      ],
      "id": "vnFC4I83lAuH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rx2S07iFXhL_"
      },
      "outputs": [],
      "source": [
        "import open3d as o3d\n",
        "def vis_pc(xyz, color_axis=-1, rgb=None):\n",
        "    # TODO move to the other module and do import in the module\n",
        "    \n",
        "    pcd = o3d.geometry.PointCloud()\n",
        "    pcd.points = o3d.utility.Vector3dVector(xyz)\n",
        "\n",
        "    if color_axis >= 0:\n",
        "        if color_axis == 3:\n",
        "            axis_vis = np.arange(0, xyz.shape[0], dtype=np.float32)\n",
        "        else:\n",
        "            axis_vis = xyz[:, color_axis]\n",
        "        min_ = np.min(axis_vis)\n",
        "        max_ = np.max(axis_vis)\n",
        "\n",
        "        colors = cm.gist_rainbow((axis_vis - min_) / (max_ - min_))[:, 0:3]\n",
        "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
        "    if rgb is not None:\n",
        "        pcd.colors = o3d.utility.Vector3dVector(rgb)\n",
        "\n",
        "     \n",
        "    print(\"Downsample the point cloud with a voxel of 0.05\")\n",
        "    downpcd = pcd.voxel_down_sample(voxel_size=0.05)\n",
        "    o3d.visualization.draw_geometries([downpcd])\n",
        "    print(\"Recompute the normal of the downsampled point cloud\")\n",
        "    downpcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(\n",
        "        radius=0.1, max_nn=30))\n",
        "    o3d.visualization.draw_plotly([downpcd])\n",
        "\n",
        "    print(\"Print a normal vector of the 0th point\")\n",
        "    print(downpcd.normals[0])\n",
        "    print(\"Print the normal vectors of the first 10 points\")\n",
        "    print(np.asarray(downpcd.normals)[:10, :])\n",
        "    print(\"\")\n",
        "    return downpcd\n",
        "downpcd=vis_pc(pointcloud)"
      ],
      "id": "rx2S07iFXhL_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SVSusOfEeU_"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "def draw_geometries(geometries):\n",
        "    graph_objects = []\n",
        "\n",
        "    for geometry in geometries:\n",
        "        geometry_type = geometry.get_geometry_type()\n",
        "        \n",
        "        if geometry_type == o3d.geometry.Geometry.Type.PointCloud:\n",
        "            points = np.asarray(geometry.points)\n",
        "            colors = None\n",
        "            if geometry.has_colors():\n",
        "                colors = np.asarray(geometry.colors)\n",
        "            elif geometry.has_normals():\n",
        "                colors = (0.5, 0.5, 0.5) + np.asarray(geometry.normals) * 0.5\n",
        "                print(\"it has normals\")\n",
        "            else:\n",
        "                geometry.paint_uniform_color((1.0, 0.0, 0.0))\n",
        "                colors = np.asarray(geometry.colors)\n",
        "\n",
        "            scatter_3d = go.Scatter3d(x=points[:,0], y=points[:,1], z=points[:,2], mode='markers', marker=dict(size=1, color=colors))\n",
        "            graph_objects.append(scatter_3d)\n",
        "\n",
        "        if geometry_type == o3d.geometry.Geometry.Type.TriangleMesh:\n",
        "            triangles = np.asarray(geometry.triangles)\n",
        "            vertices = np.asarray(geometry.vertices)\n",
        "            colors = None\n",
        "            if geometry.has_triangle_normals():\n",
        "                colors = (0.5, 0.5, 0.5) + np.asarray(geometry.triangle_normals) * 0.5\n",
        "                colors = tuple(map(tuple, colors))\n",
        "                print(\"it has normals\")\n",
        "            else:\n",
        "                colors = (1.0, 0.0, 0.0)\n",
        "            \n",
        "            mesh_3d = go.Mesh3d(x=vertices[:,0], y=vertices[:,1], z=vertices[:,2], i=triangles[:,0], j=triangles[:,1], k=triangles[:,2], facecolor=colors, opacity=0.50)\n",
        "            graph_objects.append(mesh_3d)\n",
        "        \n",
        "    fig = go.Figure(\n",
        "        data=graph_objects,\n",
        "        layout=dict(\n",
        "            scene=dict(\n",
        "                xaxis=dict(visible=False),\n",
        "                yaxis=dict(visible=False),\n",
        "                zaxis=dict(visible=False)\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "    fig.show()"
      ],
      "id": "7SVSusOfEeU_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hgV93JgcJiY"
      },
      "outputs": [],
      "source": [
        "print(np.asarray(downpcd.points))"
      ],
      "id": "6hgV93JgcJiY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmKrgs4WEW_B"
      },
      "outputs": [],
      "source": [
        "o3d.visualization.draw_geometries = draw_geometries # replace function\n",
        "o3d.visualization.draw_geometries([downpcd])\n"
      ],
      "id": "qmKrgs4WEW_B"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cb38d73"
      },
      "outputs": [],
      "source": [
        " def parse_dataset(num_points=2048):\n",
        "\n",
        "    train_points = []\n",
        "    train_labels = []\n",
        "    test_points = []\n",
        "    test_labels = []\n",
        "    class_map = {}\n",
        "    folders = glob.glob(os.path.join(DATA_DIR, \"[!README]*\"))\n",
        "\n",
        "    for i, folder in enumerate(folders):\n",
        "        print(\"processing class: {}\".format(os.path.basename(folder)))\n",
        "        # store folder name with ID so we can retrieve later\n",
        "        class_map[i] = folder.split(\"/\")[-1]\n",
        "        # gather all files\n",
        "        train_files = glob.glob(os.path.join(folder, \"train/*\"))\n",
        "        test_files = glob.glob(os.path.join(folder, \"test/*\"))\n",
        "\n",
        "        for f in train_files:\n",
        "            train_points.append(trimesh.load(f).sample(num_points))\n",
        "            train_labels.append(i)\n",
        "\n",
        "        for f in test_files:\n",
        "            test_points.append(trimesh.load(f).sample(num_points))\n",
        "            test_labels.append(i)\n",
        "        print(class_map)\n",
        "    return (\n",
        "        np.array(train_points),\n",
        "        np.array(test_points),\n",
        "        np.array(train_labels),\n",
        "        np.array(test_labels),\n",
        "        class_map,\n",
        "    )"
      ],
      "id": "9cb38d73"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1e5996ec"
      },
      "outputs": [],
      "source": [
        "NUM_POINTS = 2048\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_points, test_points, train_labels, test_labels, CLASS_MAP = parse_dataset(\n",
        "    NUM_POINTS\n",
        ")\n"
      ],
      "id": "1e5996ec"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b617b90"
      },
      "outputs": [],
      "source": [
        "def augment(points, label):\n",
        "    # jitter points\n",
        "    points += tf.random.uniform(points.shape, -0.005, 0.005, dtype=tf.float64)\n",
        "    # shuffle points\n",
        "    points = tf.random.shuffle(points)\n",
        "    return points, label\n",
        "\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_points, train_labels))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_points, test_labels))\n",
        "\n",
        "train_dataset = train_dataset.shuffle(len(train_points)).map(augment).batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.shuffle(len(test_points)).batch(BATCH_SIZE)\n"
      ],
      "id": "5b617b90"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45094c55"
      },
      "outputs": [],
      "source": [
        "def conv_bn(x, filters):\n",
        "    x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\")(x)\n",
        "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
        "    return layers.Activation(\"relu\")(x)\n",
        "\n",
        "\n",
        "def dense_bn(x, filters):\n",
        "    x = layers.Dense(filters)(x)\n",
        "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
        "    return layers.Activation(\"relu\")(x)\n"
      ],
      "id": "45094c55"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc7c7d8b"
      },
      "outputs": [],
      "source": [
        "class OrthogonalRegularizer(keras.regularizers.Regularizer):\n",
        "    def __init__(self, num_features, l2reg=0.001):\n",
        "        self.num_features = num_features\n",
        "        self.l2reg = l2reg\n",
        "        self.eye = tf.eye(num_features)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = tf.reshape(x, (-1, self.num_features, self.num_features))\n",
        "        xxt = tf.tensordot(x, x, axes=(2, 2))\n",
        "        xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n",
        "        return tf.reduce_sum(self.l2reg * tf.square(xxt - self.eye))\n"
      ],
      "id": "dc7c7d8b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90deb4e6"
      },
      "outputs": [],
      "source": [
        "def tnet(inputs, num_features):\n",
        "\n",
        "    # Initalise bias as the indentity matrix\n",
        "    bias = keras.initializers.Constant(np.eye(num_features).flatten())\n",
        "    reg = OrthogonalRegularizer(num_features)\n",
        "\n",
        "    x = conv_bn(inputs, 32)\n",
        "    x = conv_bn(x, 64)\n",
        "    x = conv_bn(x, 512)\n",
        "    x = layers.GlobalMaxPooling1D()(x)\n",
        "    x = dense_bn(x, 256)\n",
        "    x = dense_bn(x, 128)\n",
        "    x = layers.Dense(\n",
        "        num_features * num_features,\n",
        "        kernel_initializer=\"zeros\",\n",
        "        bias_initializer=bias,\n",
        "        activity_regularizer=reg,\n",
        "    )(x)\n",
        "    feat_T = layers.Reshape((num_features, num_features))(x)\n",
        "    # Apply affine transformation to input features\n",
        "    return layers.Dot(axes=(2, 1))([inputs, feat_T])\n"
      ],
      "id": "90deb4e6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02ae4f2b"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(NUM_POINTS, 3))\n",
        "\n",
        "x = tnet(inputs, 3)\n",
        "x = conv_bn(x, 64)\n",
        "x = conv_bn(x,64)\n",
        "x = tnet(x, 64)\n",
        "x = conv_bn(x, 128)\n",
        "x = conv_bn(x, 128)\n",
        "x = conv_bn(x, 1024)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = dense_bn(x, 512)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = dense_bn(x, 256)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "\n",
        "outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name=\"pointnet\")\n",
        "model.summary()\n"
      ],
      "id": "02ae4f2b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b71cc174"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "\n",
        "history=model.fit(train_dataset, epochs=20, validation_data=test_dataset)\n",
        " "
      ],
      "id": "b71cc174"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0a03557"
      },
      "outputs": [],
      "source": [
        "data = test_dataset.take(1)\n",
        "\n",
        "points, labels = list(data)[0]\n",
        "points = points[:8, ...]\n",
        "labels = labels[:8, ...]\n",
        "\n",
        "# run test data through model\n",
        "preds = model.predict(points)\n",
        "preds = tf.math.argmax(preds, -1)\n",
        "\n",
        "points = points.numpy()\n",
        "\n",
        "# plot points with predicted class and label\n",
        "fig = plt.figure(figsize=(15, 10))\n",
        "for i in range(8):\n",
        "    ax = fig.add_subplot(2, 4, i + 1, projection=\"3d\")\n",
        "    ax.scatter(points[i, :, 0], points[i, :, 1], points[i, :, 2])\n",
        "    ax.set_title(\n",
        "        \"pred: {:}, label: {:}\".format(\n",
        "            CLASS_MAP[preds[i].numpy()], CLASS_MAP[labels.numpy()[i]]\n",
        "        )\n",
        "    )\n",
        "    ax.set_axis_off()\n",
        "plt.show()\n"
      ],
      "id": "c0a03557"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13e42c64"
      },
      "outputs": [],
      "source": [
        "model.save(\"pointnet.model\")"
      ],
      "id": "13e42c64"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ep-FO21roAGy"
      },
      "outputs": [],
      "source": [
        "def plot_history(history):\n",
        "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
        "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
        "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
        "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
        "    \n",
        "    if len(loss_list) == 0:\n",
        "        print('Loss is missing in history')\n",
        "        return \n",
        "    \n",
        "    ## As loss always exists\n",
        "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
        "    \n",
        "    ## Loss\n",
        "    plt.figure(1)\n",
        "    for l in loss_list:\n",
        "        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
        "    for l in val_loss_list:\n",
        "        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
        "    \n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    \n",
        "    ## Accuracy\n",
        "    plt.figure(2)\n",
        "    for l in acc_list:\n",
        "        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
        "    for l in val_acc_list:    \n",
        "        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
        "\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "id": "Ep-FO21roAGy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EONnv7sEoGIb"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "plot_history(history)\n",
        "\n"
      ],
      "id": "EONnv7sEoGIb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eb4383b6"
      },
      "outputs": [],
      "source": [
        "print(preds\n",
        "     )"
      ],
      "id": "eb4383b6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5163c4ad"
      },
      "outputs": [],
      "source": [
        "\n",
        "     \n",
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(correct_labels,predicted_labels);\n",
        "cm\n",
        "# function from https://deeplizard.com/learn/video/0LhiS6yu2qQ\n",
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "plt.figure(figsize=(8,8))\n",
        "plot_confusion_matrix(cm,classes, normalize=True)"
      ],
      "id": "5163c4ad"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "161a4937"
      },
      "outputs": [],
      "source": [
        "print(len(test_dataset))"
      ],
      "id": "161a4937"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nSaVEvxagD9"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix1(cm, classes,\n",
        "                          normalize=False,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        title='Normalized confusion matrix'\n",
        "    else:\n",
        "        title='Confusion matrix'\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()\n",
        "    \n",
        "## multiclass or binary report\n",
        "## If binary (sigmoid output), set binary parameter to True\n",
        "def full_multiclass_report(model,\n",
        "                           x,\n",
        "                           y_true,\n",
        "                           classes,\n",
        "                           batch_size=32,\n",
        "                           binary=False):\n",
        "\n",
        "    # 1. Transform one-hot encoded y_true into their class number\n",
        "    \n",
        "    \n",
        "    # 2. Predict classes and stores in y_pred\n",
        "    y_pred = model.predict_classes(x, batch_size=batch_size)\n",
        "    \n",
        "    # 3. Print accuracy score\n",
        "    print(\"Accuracy : \"+ str(accuracy_score(y_true,y_pred)))\n",
        "    \n",
        "    print(\"\")\n",
        "    \n",
        "    # 4. Print classification report\n",
        "    print(\"Classification Report\")\n",
        "    print(classification_report(y_true,y_pred,digits=5))    \n",
        "    \n",
        "    # 5. Plot confusion matrix\n",
        "    cnf_matrix = confusion_matrix(y_true,y_pred)\n",
        "    print(cnf_matrix)\n",
        "    plot_confusion_matrix(cnf_matrix,classes=classes)"
      ],
      "id": "1nSaVEvxagD9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7ddIIs5a2Fv"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "R7ddIIs5a2Fv"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "print(classification_report(correct_labels,predicted_labels,digits=5))   "
      ],
      "metadata": {
        "id": "Klh1_SBj2sQr"
      },
      "id": "Klh1_SBj2sQr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " print(\"Accuracy : \"+ str(accuracy_score(correct_labels,predicted_labels)))"
      ],
      "metadata": {
        "id": "uRqNeYJC3n2V"
      },
      "id": "uRqNeYJC3n2V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix1(cm,classes=classes)"
      ],
      "metadata": {
        "id": "-E6XhBsw_p40"
      },
      "id": "-E6XhBsw_p40",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "482171af"
      },
      "outputs": [],
      "source": [
        "y_pred = []  # store predicted labels\n",
        "y_true = []  # store true labels\n",
        "test_data=[]\n",
        "# iterate over the dataset\n",
        "for image_batch, label_batch in test_dataset:   # use dataset.unbatch() with repeat\n",
        "   # append true labels\n",
        "   y_true.append(label_batch)\n",
        "   # compute predictions\n",
        "   preds = model.predict(image_batch)\n",
        "   # append predicted labels\n",
        "   y_pred.append(np.argmax(preds, axis = - 1))\n",
        "   test_data.append(image_batch)\n",
        "# convert the true and predicted labels into tensors\n",
        "correct_labels = tf.concat([item for item in y_true], axis = 0)\n",
        "predicted_labels = tf.concat([item for item in y_pred], axis = 0)\n",
        "test_dataset=tf.concat([item for item in test_data], axis = 0)"
      ],
      "id": "482171af"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2843fa9c"
      },
      "outputs": [],
      "source": [
        "print(concatbatches)"
      ],
      "id": "2843fa9c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7542bf4a"
      },
      "outputs": [],
      "source": [],
      "id": "7542bf4a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f9584d4"
      },
      "outputs": [],
      "source": [
        "classes=list(CLASS_MAP.values())"
      ],
      "id": "1f9584d4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3fab07a"
      },
      "outputs": [],
      "source": [
        "print(classes)"
      ],
      "id": "c3fab07a"
    },
    {
      "cell_type": "code",
      "source": [
        "history = tf.saved_model.load(\"/content/pointnet.model\")\n"
      ],
      "metadata": {
        "id": "0xJFRDBySlbl"
      },
      "id": "0xJFRDBySlbl",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}